{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn-crfsuite in g:\\miniconda3\\lib\\site-packages (0.3.6)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in g:\\miniconda3\\lib\\site-packages (from sklearn-crfsuite) (0.9.10)\n",
      "Requirement already satisfied: six in g:\\miniconda3\\lib\\site-packages (from sklearn-crfsuite) (1.16.0)\n",
      "Requirement already satisfied: tabulate in g:\\miniconda3\\lib\\site-packages (from sklearn-crfsuite) (0.9.0)\n",
      "Requirement already satisfied: tqdm>=2.0 in g:\\miniconda3\\lib\\site-packages (from sklearn-crfsuite) (4.65.0)\n",
      "Requirement already satisfied: colorama in g:\\miniconda3\\lib\\site-packages (from tqdm>=2.0->sklearn-crfsuite) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Training data shape: (609, 4)\n",
      "Validation data shape: (68, 4)\n",
      "Label Counts: Counter({'MAN_MADE_EVENT.SUICIDE_ATTACK': 326, 'MAN_MADE_EVENT.TERRORIST_ATTACK': 287, 'MAN_MADE_EVENT.SHOOT_OUT': 280, 'NATURAL_EVENT.EARTHQUAKE': 263, 'MAN_MADE_EVENT.VEHICULAR_COLLISION': 250, 'MAN_MADE_EVENT.FIRE': 228, 'MAN_MADE_EVENT.INDUSTRIAL_ACCIDENT': 194, 'NATURAL_EVENT.HEAT_WAVE': 185, 'MAN_MADE_EVENT.TRAIN_COLLISION': 139, 'NATURAL_EVENT.LAND_SLIDE': 138, 'NATURAL_EVENT.FLOODS': 136, 'NATURAL_EVENT.AVALANCHES': 135, 'MAN_MADE_EVENT.RIOTS': 125, 'NATURAL_EVENT.HURRICANE': 117, 'MAN_MADE_EVENT.TRANSPORT_HAZARDS': 115, 'NATURAL_EVENT.FOREST_FIRE': 114, 'NATURAL_EVENT.TORNADO': 112, 'NATURAL_EVENT.HAIL_STORMS': 103, 'NATURAL_EVENT.STORM': 101, 'NATURAL_EVENT.COLD_WAVE': 99, 'NATURAL_EVENT.VOLCANO': 96, 'MAN_MADE_EVENT.AVIATION_HAZARD': 93, 'NATURAL_EVENT.BLIZZARD': 67, 'NATURAL_EVENT.CYCLONE': 66, 'MAN_MADE_EVENT.NORMAL_BOMBING': 47, 'MAN_MADE_EVENT.ARMED_CONFLICTS': 23, 'NATURAL_EVENT.DROUGHT': 5, 'NATURAL_EVENT.TSUNAMI': 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\miniconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Performance:\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "    MAN_MADE_EVENT.ARMED_CONFLICTS       1.00      1.00      1.00         3\n",
      "    MAN_MADE_EVENT.AVIATION_HAZARD       1.00      1.00      1.00        15\n",
      "               MAN_MADE_EVENT.FIRE       1.00      1.00      1.00        30\n",
      "MAN_MADE_EVENT.INDUSTRIAL_ACCIDENT       1.00      1.00      1.00        32\n",
      "     MAN_MADE_EVENT.NORMAL_BOMBING       1.00      1.00      1.00         4\n",
      "              MAN_MADE_EVENT.RIOTS       1.00      1.00      1.00         9\n",
      "          MAN_MADE_EVENT.SHOOT_OUT       1.00      1.00      1.00        28\n",
      "     MAN_MADE_EVENT.SUICIDE_ATTACK       1.00      1.00      1.00        39\n",
      "   MAN_MADE_EVENT.TERRORIST_ATTACK       1.00      1.00      1.00        78\n",
      "    MAN_MADE_EVENT.TRAIN_COLLISION       1.00      1.00      1.00        14\n",
      "  MAN_MADE_EVENT.TRANSPORT_HAZARDS       1.00      1.00      1.00        25\n",
      "MAN_MADE_EVENT.VEHICULAR_COLLISION       1.00      1.00      1.00        37\n",
      "          NATURAL_EVENT.AVALANCHES       1.00      1.00      1.00        29\n",
      "            NATURAL_EVENT.BLIZZARD       1.00      1.00      1.00        17\n",
      "           NATURAL_EVENT.COLD_WAVE       1.00      1.00      1.00        23\n",
      "             NATURAL_EVENT.CYCLONE       1.00      1.00      1.00         8\n",
      "             NATURAL_EVENT.DROUGHT       1.00      1.00      1.00         1\n",
      "          NATURAL_EVENT.EARTHQUAKE       1.00      1.00      1.00        29\n",
      "              NATURAL_EVENT.FLOODS       1.00      1.00      1.00        23\n",
      "         NATURAL_EVENT.FOREST_FIRE       1.00      1.00      1.00        30\n",
      "         NATURAL_EVENT.HAIL_STORMS       1.00      1.00      1.00        18\n",
      "           NATURAL_EVENT.HEAT_WAVE       1.00      1.00      1.00        22\n",
      "           NATURAL_EVENT.HURRICANE       1.00      1.00      1.00        14\n",
      "          NATURAL_EVENT.LAND_SLIDE       1.00      1.00      1.00        34\n",
      "               NATURAL_EVENT.STORM       1.00      1.00      1.00        15\n",
      "             NATURAL_EVENT.TORNADO       1.00      1.00      1.00        15\n",
      "             NATURAL_EVENT.VOLCANO       1.00      1.00      1.00        17\n",
      "\n",
      "                          accuracy                           1.00       609\n",
      "                         macro avg       1.00      1.00      1.00       609\n",
      "                      weighted avg       1.00      1.00      1.00       609\n",
      "\n",
      "Validation Set Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "g:\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "g:\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "g:\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "g:\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "g:\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "    MAN_MADE_EVENT.AVIATION_HAZARD       1.00      1.00      1.00         1\n",
      "               MAN_MADE_EVENT.FIRE       1.00      0.88      0.93         8\n",
      "MAN_MADE_EVENT.INDUSTRIAL_ACCIDENT       1.00      1.00      1.00         3\n",
      "     MAN_MADE_EVENT.NORMAL_BOMBING       0.00      0.00      0.00         1\n",
      "          MAN_MADE_EVENT.SHOOT_OUT       1.00      0.86      0.92         7\n",
      "     MAN_MADE_EVENT.SUICIDE_ATTACK       0.67      1.00      0.80         2\n",
      "   MAN_MADE_EVENT.TERRORIST_ATTACK       0.70      1.00      0.82         7\n",
      "    MAN_MADE_EVENT.TRAIN_COLLISION       0.50      1.00      0.67         2\n",
      "  MAN_MADE_EVENT.TRANSPORT_HAZARDS       0.00      0.00      0.00         4\n",
      "MAN_MADE_EVENT.VEHICULAR_COLLISION       0.78      1.00      0.88         7\n",
      "            NATURAL_EVENT.BLIZZARD       0.75      0.75      0.75         4\n",
      "           NATURAL_EVENT.COLD_WAVE       1.00      1.00      1.00         4\n",
      "          NATURAL_EVENT.EARTHQUAKE       0.75      1.00      0.86         3\n",
      "              NATURAL_EVENT.FLOODS       0.00      0.00      0.00         0\n",
      "           NATURAL_EVENT.HEAT_WAVE       1.00      1.00      1.00         3\n",
      "           NATURAL_EVENT.HURRICANE       1.00      1.00      1.00         1\n",
      "          NATURAL_EVENT.LAND_SLIDE       1.00      1.00      1.00         3\n",
      "               NATURAL_EVENT.STORM       1.00      0.50      0.67         2\n",
      "             NATURAL_EVENT.TORNADO       0.00      0.00      0.00         2\n",
      "             NATURAL_EVENT.VOLCANO       1.00      1.00      1.00         4\n",
      "\n",
      "                          accuracy                           0.84        68\n",
      "                         macro avg       0.71      0.75      0.71        68\n",
      "                      weighted avg       0.79      0.84      0.80        68\n",
      "\n",
      "Transformed Labels - Training Set Performance:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "MAN_MADE_EVENT       1.00      1.00      1.00       314\n",
      " NATURAL_EVENT       1.00      1.00      1.00       295\n",
      "\n",
      "      accuracy                           1.00       609\n",
      "     macro avg       1.00      1.00      1.00       609\n",
      "  weighted avg       1.00      1.00      1.00       609\n",
      "\n",
      "Transformed Labels - Validation Set Performance:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "MAN_MADE_EVENT       0.98      1.00      0.99        42\n",
      " NATURAL_EVENT       1.00      0.96      0.98        26\n",
      "\n",
      "      accuracy                           0.99        68\n",
      "     macro avg       0.99      0.98      0.98        68\n",
      "  weighted avg       0.99      0.99      0.99        68\n",
      "\n",
      "Transformed Probabilities - Training Set Performance:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "MAN_MADE_EVENT       1.00      1.00      1.00       314\n",
      " NATURAL_EVENT       1.00      1.00      1.00       295\n",
      "\n",
      "      accuracy                           1.00       609\n",
      "     macro avg       1.00      1.00      1.00       609\n",
      "  weighted avg       1.00      1.00      1.00       609\n",
      "\n",
      "Transformed Probabilities - Validation Set Performance:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "MAN_MADE_EVENT       1.00      1.00      1.00        42\n",
      " NATURAL_EVENT       1.00      1.00      1.00        26\n",
      "\n",
      "      accuracy                           1.00        68\n",
      "     macro avg       1.00      1.00      1.00        68\n",
      "  weighted avg       1.00      1.00      1.00        68\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRF Model F1 Score: 0.2457701854299099\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from utils import transform_label, transform_probs, get_entity_info, CLASS_MAP  # Import custom utility functions\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Install sklearn-crfsuite library\n",
    "%pip install sklearn-crfsuite\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Load the training data from the JSON file\n",
    "df = pd.read_json(\"./data/processed/hindi_train.json\", orient=\"records\", lines=True)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "df_train, df_valid = train_test_split(df, test_size=0.10, random_state=42)\n",
    "\n",
    "# Print the shapes of the training and validation sets\n",
    "print(\"Training data shape:\", df_train.shape)\n",
    "print(\"Validation data shape:\", df_valid.shape)\n",
    "\n",
    "# Count the occurrence of labels in the training data\n",
    "label_counts = sum([Counter(l) for l in df.labels], Counter())\n",
    "print(\"Label Counts:\", label_counts)\n",
    "\n",
    "# Convert labels to indices based on the maximum occurrence\n",
    "X_train = df_train[\"tokens\"]\n",
    "y_train = df_train.labels.apply(pd.Series).idxmax(axis=1)\n",
    "\n",
    "X_valid = df_valid[\"tokens\"]\n",
    "y_valid = df_valid.labels.apply(pd.Series).idxmax(axis=1)\n",
    "\n",
    "\n",
    "# Define and train a RandomForestClassifier pipeline\n",
    "clf = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(tokenizer=lambda x: x, preprocessor=lambda x: x)),\n",
    "    (\"model\", RandomForestClassifier())\n",
    "])\n",
    "clf.fit(df_train[\"tokens\"], y_train)\n",
    "\n",
    "# Evaluate the model on the training and validation sets\n",
    "print(\"Training Set Performance:\")\n",
    "print(classification_report(y_true=y_train, y_pred=clf.predict(df_train[\"tokens\"])))\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_true=y_valid, y_pred=clf.predict(df_valid[\"tokens\"])))\n",
    "\n",
    "# Further evaluation of the model with transformed labels and probabilities\n",
    "y_train_transformed = transform_label(y_train)\n",
    "y_valid_transformed = transform_label(y_valid)\n",
    "print(\"Transformed Labels - Training Set Performance:\")\n",
    "print(classification_report(y_true=y_train_transformed, y_pred=transform_label(clf.predict(df_train[\"tokens\"]))))\n",
    "print(\"Transformed Labels - Validation Set Performance:\")\n",
    "print(classification_report(y_true=y_valid_transformed, y_pred=transform_label(clf.predict(df_valid[\"tokens\"]))))\n",
    "\n",
    "# Generate predictions and probabilities\n",
    "y_valid_proba = clf.predict_proba(df_valid[\"tokens\"])\n",
    "\n",
    "# Convert class labels to corresponding categories\n",
    "clf_map = {c: c.split(\".\")[0] for c in clf.classes_}\n",
    "\n",
    "# Transform probabilities and evaluate\n",
    "print(\"Transformed Probabilities - Training Set Performance:\")\n",
    "print(classification_report(y_true=y_train_transformed, y_pred=transform_probs(clf.predict_proba(df_train[\"tokens\"]), clf)))\n",
    "print(\"Transformed Probabilities - Validation Set Performance:\")\n",
    "print(classification_report(y_true=y_valid_transformed, y_pred=transform_probs(y_valid_proba, clf)))\n",
    "\n",
    "# Define feature extraction functions for CRF\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    #postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        #'postag': postag,\n",
    "        #'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        #postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            #'-1:postag': postag1,\n",
    "            #'-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        #postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            #'+1:postag': postag1,\n",
    "            #'+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]\n",
    "\n",
    "\n",
    "def df_to_Xy(df):\n",
    "    sentences = [list(zip(*row[[\"tokens\", \"tags\"]])) for i, row in df.iterrows()]\n",
    "    X = [sent2features(s) for s in sentences]\n",
    "    y = [sent2labels(s) for s in sentences]\n",
    "    return X, y\n",
    "\n",
    "# Prepare data for CRF\n",
    "X_train, y_train = df_to_Xy(df_train)\n",
    "X_valid, y_valid = df_to_Xy(df_valid)\n",
    "\n",
    "# Train CRF model\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='ap',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=False\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with CRF model\n",
    "y_pred = crf.predict(X_valid)\n",
    "\n",
    "# Evaluate CRF model performance\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "f1_score = metrics.flat_f1_score(y_valid, y_pred, average='weighted', labels=labels)\n",
    "#print(\"CRF Model F1 Score:\", f1_score)\n",
    "\n",
    "# Load test data\n",
    "df_test = pd.read_json(\"./data/processed/hindi_test.json\", orient=\"records\", lines=True)\n",
    "\n",
    "def generate_xml(entity_info, docid, simple=False):\n",
    "    root = ET.Element(\"DOCUMENT\") \n",
    "    docid_e = ET.Element(\"DOCID\")\n",
    "    docid_e.text = f\"{docid}\"\n",
    "    root.append(docid_e) \n",
    "    for info in entity_info:\n",
    "        label = info[\"label\"]\n",
    "        subtype = None\n",
    "        if label.startswith(tuple(CLASS_MAP.keys())):\n",
    "            label, subtype = label.split(\".\")\n",
    "            label = CLASS_MAP[label]\n",
    "        elif simple:\n",
    "            continue\n",
    "        if label.endswith(\"-ARG\"):\n",
    "            label = label.split(\"-ARG\")[0]\n",
    "            subtype = None\n",
    "        elem = ET.Element(label.upper())\n",
    "        if subtype:\n",
    "            elem.attrib[\"TYPE\"] = subtype.upper()\n",
    "        elem.text = info[\"entity_phrase\"]\n",
    "        root.append(elem)\n",
    "    return root\n",
    "\n",
    "from pathlib import Path\n",
    "base_path = Path(f\"./data/Output/\")\n",
    "\n",
    "def create_files(df_test):\n",
    "    X_test, y_test = df_to_Xy(df_test)\n",
    "    y_pred = crf.predict(X_test)\n",
    "    for pred, (idx, row) in zip(y_pred, df_test.iterrows()):\n",
    "        entity_info = get_entity_info(pred, row[\"tokens\"])\n",
    "        docid = row[\"docid\"]\n",
    "        for task, simple in enumerate([True, False], start=1):\n",
    "            root = generate_xml(entity_info, docid, simple=simple)\n",
    "            out_path = base_path / f\"Task_{task}\" / f\"{docid}.xml\"\n",
    "            with open(out_path, \"wb\") as fp:  # Open file for writing in binary mode\n",
    "                tree = ET.ElementTree(root)\n",
    "                tree.write(fp, encoding=\"utf-8\")\n",
    "\n",
    "# Generate XML output files\n",
    "create_files(df_test)\n",
    "print(\"Output saved in data\\Output files in XML format\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
